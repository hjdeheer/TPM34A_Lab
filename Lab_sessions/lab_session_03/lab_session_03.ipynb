{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPM034A Machine Learning for socio-technical systems \n",
    "## `Lab session 03:  Decision trees and Random forests`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2022**<br>\n",
    "**Instructor:** Sander van Cranenburgh <br>\n",
    "**TAs:**  Francisco Garrido Valenzuela & Lucas Spierenburg <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Show and reinforce how models and ideas presented in class are used in practice.<br>\n",
    "* Help you gather hands-on machine learning skills.<br>\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.<br> \n",
    "* Not graded and do not have to be submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Workspace set-up`\n",
    "**Option 1: Google Colab**<br>\n",
    "Uncomment the following cells code lines if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/TPM34A/Q2_2022\n",
    "#!pip install -r Q2_2022/requirements_colab.txt\n",
    "#!mv \"/content/Q2_2022/Lab_sessions/lab_session_03/data\" /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Local environment**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment. This will install all dependencies on your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Predicting primary school outflow` <br>\n",
    "In this lab session we will use decision trees and random forests to predict the **share of school leavers advised to go to higher education (HAVO, VWO)**. In the last year of primary education, schools give their students an advice on their further education. Data on the school advices are collected by the ministry of education to monitor school outflow. These data are also widely used by parents who use them to help choose the primary school for their offspring. Various websites have recently emerged that make these school data easily accessible, see e.g. the screenshot below taken from [allecijfers.nl](https://allecijfers.nl/basisschool/freinetschool-delft/) showing the stats for de Freinet school in Delft.<br>\n",
    "<br>\n",
    "![website_reporting_outflow](website_screenshot.jpg)\n",
    "<br>\n",
    "<br>\n",
    "In this lab session we are going to analyse these data. In particular, our **aim** is to answer the following 2 Research Questions (RQs) that parents may consider upon choosing a school for their offspring:\n",
    "* RQ1: Is the share of school leavers with an advice for higher education, larger at **large schools** than at **small schools**, or vice versa?\n",
    "* RQ2: Does the type of school (i.e its **denomination**) matters for the share of school leavers with an advice for higher education?<br> \n",
    "\n",
    "**Background information on the Dutch school system**<br>\n",
    "The majority of the schools in the Netherlands are grounded in specific religious or philosophical beliefs, such as Christianity, Protestantism and Anthroposophy. This is called school denomination. Schools that are not grounded in such belief are called \"Openbare scholen\", meaning \"Public schools\". Importantly, virtually all schools in the Netherlands are funded by the federal government. Thus, unlike their counterparts in various Anglo-Saxon countries, public schools are generally equally well-funded as schools with specific denominations. \n",
    "<br>\n",
    "\n",
    "**Neighboorhood characteristics**<br>\n",
    "In the literature, there is ample evidence that neighboorhood characteristics correlate with educational achievements [see e.g. Owens 2018](https://journals.sagepub.com/doi/full/10.1177/0038040717741180). Accordingly, these characteristics can be expected to correlate with our target feature: the share of school leavers with an advice for higher education.<br>\n",
    "\n",
    "The **conceptual model** for this lab session is shown below. Accordingly, to do the proposed analyses we have pulled together data on:\n",
    "* School characteristics. These data include the size and denomination of schools (`TOTAL_STUDENTS`, `DENOMINATION`) as well as the share of the school leavers with an educational advice of HAVO or Higher (`SHARE_HIGH`)\n",
    "* Neighbourhood characteristics. Data on the neighbourhoods in which the schools are located (population density, demography, real-estate value...).\n",
    "\n",
    "![conceptual_model_lab_ session3](Conceptual_model_lab_session3.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Learning objectives**. After completing the following exercises you will be able to: <br>\n",
    "1. Apply multiple ML models to the same data set, including `Linear multiple regressions`, `Decision trees` and `Random Forests`\n",
    "2. Identify the most important features and their impact on the target feature<br>\n",
    "3. Explore the pros and cons of each model, and how models can complement each other to answer specific research questions <br>\n",
    "\n",
    "\n",
    "#### `Organisation`\n",
    "This lab session comprises **`3`** parts:\n",
    "1. Loading, exploring and cleaning the data\n",
    "2. Training multiple models: `Linear multiple regressions`, `Decision trees` and `Random Forests`\n",
    "3. Comparing and reflecting on the model performances and their outcomes\n",
    "\n",
    "and comprises **`6`** `exercises`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python packages and modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from os import getcwd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,VotingRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer,log_loss\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Setting\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Loading, exploring and cleaning the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas DataFrame\n",
    "data_folder = Path('data')\n",
    "df_schools = pd.read_csv(data_folder/'school_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating prediction models, we have to understand what features are in your data.<br><br>\n",
    "Let's start with inspecting the **target feature** `SHARE_HIGH`<br>\n",
    "`SHARE_HIGH` is the share of the students that have received the advice for further education of HAVO, or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schools['SHARE_HIGH'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this histogram two observations can be made:\n",
    "1. The target feature `SHARE_HIGH` is by and large normally distributed.\n",
    "2. What catches the eye though, is the uptick around zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's inspect the first (explanatory) feature of interest, i.e. `TOTAL_STUDENTS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schools['TOTAL_STUDENTS'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some buurt features depend on their size (e.g. the number of people under 15 years old for instance).\n",
    "# We divide these feature by the total number of inhabitants in the neighbourhood (buurt): thus, `number_inhabitants_5`.\n",
    "\n",
    "# Features to divide by the buurt population.\n",
    "f2divide = ['Men_6', 'Women_7', 'k_0To15Years_8', 'k_15To25Years_9',\n",
    "            'k_25To45Years_10', 'k_45To65Years_11', 'k_65YearsOrder_12',\n",
    "            'Single_13', 'Married_14', 'Divorced_15', 'Widowed_16',\n",
    "            'WesternTotal_17', 'Non-WesternTotal_18', 'Morocco_19',\n",
    "            'DutchAntillesAndAruba_20', 'Suriname_21', 'Turkey_22',\n",
    "            'OtherNon-Western_23', 'HouseholdsTotal_28', 'Single_Households_29',\n",
    "            'HouseholdsWithoutChildren_30', 'HouseholdsWithChildren_31',\n",
    "            'Housing_Stock_34','Motorcycles_104','PassengerCarTotal_99']\n",
    "\n",
    "df_schools.loc[:,f2divide] = df_schools.loc[:,f2divide].div(df_schools['number_inhabitants_5'], axis = 0)\n",
    "\n",
    "# Some other features are present both in absolute and relative terms. \n",
    "# In that case, we keep only the relative terms.\n",
    "f2remove = ['BirthTotal_24','MortalityTotal_26','EducationLevelLow_64', 'EducationLevelMedium_65',\n",
    "       'EducationLevelHigh_66','PassengerCarFuelBenzine_100', 'PassengerCarSOverigeFuel_101']\n",
    "\n",
    "df_schools = df_schools.drop(columns = f2remove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:skyblue\">Exercise 1: Do school with more than the average number of students have on average higher advices?</span> \n",
    "To get a first hunch regarding the first research question:<br>\n",
    "`A` Create a new column called `SIZE` in the dataframe, consisting of two groups (0,1):<br> \n",
    "    0 --> `TOTAL_STUDENTS` smaller than the mean number of students<br>\n",
    "    1 --> `TOTAL_STUDENTS` larger than the mean number of students<br>\n",
    "`B` Put the results in a boxplot, where *y* is the target feature (SHARE_HIGH). <br>\n",
    "`C` What is your first hunch: do large schools perform 'better'? <br>\n",
    "`D` Suppose that large schools do perform better, what could be a driving force the difference that we observe? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE YOUR ANSWERS HERE (Use as many cells as you need)\n",
    "# ANSWERS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the second feature of interest, i.e. the `DENOMINATION`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schools['DENOMINATION'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the histogram, the distribution of \"DENOMINATION\" is highly skewed. Therefore, for our later analyses, we merge the little occuring categories into one new category called \"DENOMINATION_Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace little occuring denomination with the category 'Other\n",
    "\n",
    "# Create a list with little occuring denominations \n",
    "df_schools_denom_count = df_schools['DENOMINATION'].value_counts()\n",
    "\n",
    "# Identify the denominations to be pulled together\n",
    "denomination_threshold = 100\n",
    "denom2merge= list(df_schools_denom_count.index[df_schools_denom_count<denomination_threshold])\n",
    "\n",
    "# Replace little occuring denomitations with Other\n",
    "df_schools['DENOMINATION'].replace(denom2merge,'Other',inplace = True)\n",
    "\n",
    "# Show the new categories and their counts\n",
    "df_schools['DENOMINATION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the spread and skewness of \"SHARE_HIGH\" across school with different \"DENOMINATION_ESTABLISHMENT\". Hence, we create a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize =(15,4))\n",
    "sns.boxplot(x='DENOMINATION', y='SHARE_HIGH', data=df_schools, ax= ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot shows no particular trend betweem denomination and school performance (i.e. SHARE_HIGH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features that we want to us in our ML models must be either *floats* or *integers*. Hence, we must convert categorial features (strings) of interest into dummy coded features. The only categorical feature of interest is `DENOMINATION`. Other categorical features, such as `INSTITUTION_NAME_BRANCH`, `LOCALITY_NAME`, `PROVINCE`, and  `SPECIES_PO` do not seem to be of interest and not converted into dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['DENOMINATION']\n",
    "df_schools_cat = pd.get_dummies(df_schools[cat_features], columns = cat_features)\n",
    "\n",
    "# Concatenate the categorical data and the original df\n",
    "df_schools = pd.concat([df_schools,df_schools_cat], axis =1)\n",
    "\n",
    "# Show the first line of the data frame\n",
    "df_schools.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify other urban or school related features that could help predict the target (SHARE_HIGH), we create a heatmap showing the correlations across the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of correlations\n",
    "# Create plot\n",
    "fig, axes = plt.subplots(figsize=(30, 30))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = df_schools.corr()\n",
    "\n",
    "# Create upper triangular matrix to mask the upper triangular part of the heatmap\n",
    "corr_mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Generate a custom diverging colormap (because it looks better)\n",
    "corr_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, mask = corr_mask, cmap=corr_cmap, annot=False,square = True, linewidths=.5, ax = axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are specifically interested in the features that correlate with `HIGH_SHARE`. If a feature does not correlate with the target, it is unlikely it will help the model predict the target. Therefore, we create a list with 30 features that correlate strongest with the target feature. These features will be used in to train the ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute absolute correlations with the target \n",
    "df_corr = corr[['SHARE_HIGH']].abs().sort_values(by=['SHARE_HIGH'],ascending=False).T\n",
    "\n",
    "# Sort the features based the the strength of the correlation\n",
    "features_corr_sorted  = list(df_corr.keys())\n",
    "\n",
    "# Create list with the 30 most strongly correlated features, (we start at the index 1 to exclude the target itself)\n",
    "features_corr = features_corr_sorted[1:31]\n",
    "print(f'Features with the strongest correlation with the target:\\n {features_corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of whether e.g. `DENOMINATION` and `TOTAL_STUDENTS` correlate with the target, we must include them in our list of features. TOTAL_STUDENTS is already in the list of features that strongly correlate with the target. So, we only have to add the list of features of the denominations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_corr + list(df_schools_cat.keys())\n",
    "print(f'Total list of features:\\n {features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the ranges of our features. This is relevant to know when interpreting the results of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schools[features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the train and test data sets, which we will use to train our ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data \n",
    "\n",
    "# Create a df with the features only \n",
    "X = df_schools[features]\n",
    "\n",
    "# Target\n",
    "Y = df_schools.loc[:,'SHARE_HIGH']\n",
    "\n",
    "# Split the data into a train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Training multiple models: Regression model, Decision tree, and a Random forest**<br>\n",
    "Often, a researcher does not know beforehand which sort of model will do well, and which will not. Therefore, ML researchers often apply multiple models to their task and pull together their outcomes.<br>\n",
    "Next, we are going to apply 3 models:\n",
    "1. Regression model (benchmark model)<br>\n",
    "2. Decision tree<br>\n",
    "3. Random Forest<br>\n",
    "\n",
    "As we will see, each of these models provide complementary insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are going to compare different models, we create a custom evaluation function that allows us to swiftly report the following stats for the train and test data:\n",
    "* mean square error\n",
    "* mean absolute error\n",
    "* R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression_perf(model, X_train, X_test, Y_train, Y_test):\n",
    "    \n",
    "    # Make prediction with the trained model\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Create a function that computes the MSE, MAE, and R2\n",
    "    def perfs(Y,Y_pred):\n",
    "        mse = mean_squared_error(Y,Y_pred)\n",
    "        mae = mean_absolute_error(Y,Y_pred)\n",
    "        R2 = r2_score(Y,Y_pred)\n",
    "        return mse,mae,R2\n",
    "\n",
    "    # Apply the perfs function to the train and test data sets\n",
    "    mse_train, mae_train, r2_train = perfs(Y_train,Y_pred_train)\n",
    "    mse_test,  mae_test , r2_test  = perfs(Y_test,Y_pred_test)\n",
    "        \n",
    "    # Print results\n",
    "    print('Performance')\n",
    "    print(f'Mean Squared  Error Train | Test: \\t{mse_train:>7.4f}\\t|  {mse_test:>7.4f}')\n",
    "    print(f'Mean Absolute Error Train | Test: \\t{mae_train:>7.4f}\\t|  {mae_test:>7.4f}')\n",
    "    print(f'R2                  Train | Test: \\t{ r2_train:>7.4f}\\t|  {r2_test:>7.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. Linear multiple regression model\n",
    "This model usually serves as a benchmark when creating ML models. Therefore, we start with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a multiple linear regression model\n",
    "regr = LinearRegression(fit_intercept = True)\n",
    "\n",
    "# Fit the model on the training data\n",
    "regr.fit(X_train,Y_train)\n",
    "\n",
    "# Evaluate the performance of the trained model\n",
    "eval_regression_perf(regr, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "# We take an ML approach (i.e. we use a train and tests set). But, if we deem the assumptions one would take from a statistical approach plausible, \n",
    "# then the weights obtained here are also interpretable. Let's therefore print the weights of the trained model\n",
    "print('Weights')\n",
    "print(f'Intercept: \\t\\t\\t\\t\\t\\t {regr.intercept_:>7.4f}')\n",
    "for n in range(len(regr.coef_)):\n",
    "    print(f'Weight_{X.keys()[n]:32s} \\t\\t {regr.coef_[n]:>7.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, we can make several inferences:\n",
    "1. The model fit is not great but also not very bad (R2 of ~0.35)\n",
    "2. The model does not seem to overfit the data: it attains the same performance on the test as on the train data sets\n",
    "3. From the positive weight associated with TOTAL_STUDENTS, we tentatively conclude that larger schools result in on avg higher share of advices for higher education.\n",
    "4. From the weights associated with school denomination, we tentatively conclude that some denominations might impact on the share of advices for higher education.\n",
    "5. From the remaining weights, we infer that their signs are mostly in line with intuition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Decision tree\n",
    "The next ML model we will try on these data is the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a decision tree\n",
    "max_depth =4\n",
    "max_leaf_nodes = 8\n",
    "min_samples_leaf = 100\n",
    "dt = DecisionTreeRegressor(criterion = \"squared_error\", max_depth=max_depth, max_leaf_nodes = max_leaf_nodes,min_samples_leaf=min_samples_leaf,random_state=5)\n",
    "\n",
    "# Train the decision tree\n",
    "dt.fit(X_train,Y_train)\n",
    "\n",
    "# Evaluate the performance of the trained model\n",
    "eval_regression_perf(dt, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "# Visualise the decision tree\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(dt, feature_names = features, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the decision tree, we can make several observations:\n",
    "1. Compared to the regression model, the model fit (in terms of e.g. R2) has substantially improved\n",
    "2. The decison tree does not seem to over fit: the performance of the train and test data are more or less the same.\n",
    "3. The tree is easily interpretable. Moreover, the tree structure (splits) are in line with intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:skyblue\">Exercise 2: Manually navigate through the decision tree to obtain a prediction for the first instance of X_test (X_test.loc[0])</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE YOUR ANSWERS HERE (Use as many cells as you need)\n",
    "# ANSWERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which features are found to be most important to our Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,12))\n",
    "sns.barplot(y=features,x=dt.feature_importances_, ax = ax).set(title='Feature importance to predict share of school outflow that is high')\n",
    "ax.set_xlabel('Feature importance')\n",
    "\n",
    "# Print most important features\n",
    "sorted_indices = np.argsort(dt.feature_importances_)[::-1]\n",
    "most_imp_features_dt = [features[i] for i in sorted_indices]\n",
    "print(f'Top 5 most important features:\\n {most_imp_features_dt[:5]}')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the importance plot, we can draw several conclusions:\n",
    "1. Most features seem not to help predict the target: many features attain a (nearly) zero feature_importances\n",
    "2. Just four features seem important to predict the target: 'TOTAL_STUDENTS', 'pctEducationLevelHigh', 'pctEducationLevelLow', 'AverageWOZValueOfHomes_35'. These feature are in line with expectations.\n",
    "3. The school denomination seems unimportant in the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:skyblue\">Exercise 3: Try to improve the model fit of the decision tree, by testing different numbers for:</span> \n",
    "* max_depth <br>\n",
    "* max_leaf_nodes<br>\n",
    "* min_samples_leaf<br>\n",
    "\n",
    "How does each of these hyperparameters affects:<br>\n",
    "`A` The size of the tree<br>\n",
    "`B` Model performance, in terms of R2. <br>\n",
    "`C` Feature importance <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE YOUR ANSWERS HERE (Use as many cells as you need)\n",
    "# ANSWERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. Random Forest\n",
    "Lastly, we are going to try a RF on these data. RFs are known to attain a high model performance on a wide range of regression and classification tasks. \n",
    "<br>\n",
    "Instead of manually searching for the optimal hyperparameters for the RF, which is laborious, let's use sk-learn's GridSearchCV functionality to automate the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RF object\n",
    "rf_gs = RandomForestRegressor(n_estimators=250,criterion= \"squared_error\",random_state=5)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "hyperparameter_space = {\n",
    "    'max_depth': [5,7, 9, 11],\n",
    "    'max_leaf_nodes': [20,30],\n",
    "    'min_samples_leaf': [50, 100],\n",
    "    'max_features':[0.5,0.7,0.9]}\n",
    "\n",
    "# Create scoring function\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "\n",
    "# Create the grid_search object, with using the MLP classifier\n",
    "folds = 5 # Number of cross validation splits\n",
    "rf_gridsearch = GridSearchCV(rf_gs, hyperparameter_space, n_jobs=-1, cv=folds, scoring=scorer, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the training/gridsearch\n",
    "# Note that this is computationally expensive! \n",
    "# It may take up to 5 minutes, since multiple models need to be trained multiple times\n",
    "rf_gridsearch.fit(X_train,Y_train)\n",
    "print(f'Optimal hyperparameters:\\n{rf_gridsearch.best_params_}')\n",
    "print(f'Mean Squared Error:\\t{(-rf_gridsearch.best_score_):0.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters of the Random Forest to the best values found, e.g. \n",
    "max_depth = 9\n",
    "max_features = 0.9\n",
    "max_leaf_nodes = 30\n",
    "min_samples_leaf = 50\n",
    "\n",
    "# Create the Random Forest object with the best hyperparameters\n",
    "rf = RandomForestRegressor(criterion = \"squared_error\", n_estimators=1000, max_features=max_features, max_depth=max_depth, max_leaf_nodes = max_leaf_nodes,min_samples_leaf=min_samples_leaf,random_state=5)\n",
    "\n",
    "# Train the Randon Forest\n",
    "rf.fit(X_train,Y_train)\n",
    "\n",
    "# Evaluate the performance of the hyperparameter optimised RF model\n",
    "eval_regression_perf(rf,X_train,X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To obtain an understanding of the complexity of the learned trees, we visualise one of the decision trees populating the forest\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "# Tree id to visualise (integer between 0 and n_estimators). You can visualise different trees to assess their diversity\n",
    "vis_tree = 0\n",
    "\n",
    "# Create the tree plot\n",
    "tree.plot_tree(rf.estimators_[vis_tree], feature_names = features, filled=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which features are found to be most important to our Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "fig, ax = plt.subplots(figsize=(8,10))\n",
    "sns.barplot(y=features,x=rf.feature_importances_, ax = ax).set(title='Feature importance to predict share of school outflow that is \"High\"')\n",
    "ax.set_xlabel('Feature importance')\n",
    "\n",
    "# Print most important features\n",
    "sorted_indices = np.argsort(rf.feature_importances_)[::-1]\n",
    "most_imp_features_rf = [features[i] for i in sorted_indices]\n",
    "print(f'Top 5 most important features:\\n {most_imp_features_rf[:6]}')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:skyblue\">Exercise 4: Compare the results of the Random forest with those of the Decision tree, in terms of fit, trees, and feature importance</span> \n",
    "`A` What difference do you see in terms of model performance?<br>\n",
    "`B` What difference do you see in terms of the tree structure? (hint: visualise different trees from the forest to assess diversity) <br>\n",
    "`C` What difference do you see in terms of the discovered feature performances? Specifically, also look at TOTAL_STUDENTS and DENOMINATION<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE YOUR ANSWERS HERE (Use as many cells as you need)\n",
    "# ANSWERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Comparing and reflecting on the model performances and their outcomes** \n",
    "\n",
    "Often it helps the researcher to pull together the outcomes of multiple models. The idea of doing this is closely related to wisdom of the crowd principle. If multiple different model point towards the same conclusion, then the researcher has compounding evidence. In contrast, if different models point towards different conclusions, then the researcher knows the conclusions are weak(er) and sensitive to the choice of model.<br>\n",
    "Let's pull together the predictions of the 3 ML models, and show them next to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter true shares (x-axis) against the predicted shares by the different ML models (y-axis)\n",
    "fig, ax = plt.subplots(1,3,figsize=(18,4))\n",
    "ax[0].scatter(x = Y_test, y = regr.predict(X_test), s = 8, alpha = 0.8, c = '#ff7f0e', label = f'Regression | R2 = {regr.score(X_test,Y_test):0.3f}')\n",
    "ax[1].scatter(x = Y_test, y = dt.predict(X_test),   s = 8, alpha = 0.8, c = '#2ca02c', label = f'Decision tree | R2 = {dt.score(X_test,Y_test):0.3f}')\n",
    "ax[2].scatter(x = Y_test, y = rf.predict(X_test),   s = 8, alpha = 0.8, c = '#d62728', label = f'Random Forest | R2 = {rf.score(X_test,Y_test):0.3f}')\n",
    "\n",
    "# Add labels, legend, and title to each plot\n",
    "for n in range(0,3,1):\n",
    "    ax[n].set_xlabel('True share')\n",
    "    ax[n].set_ylabel('Predicted share')\n",
    "    ax[n].set_xlim(0,1)\n",
    "    ax[n].set_ylim(0,1)\n",
    "    ax[n].legend()\n",
    "    ax[n].set_title('True versus predicted SHARE_HIGH (test data)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:skyblue\">Exercise 5:  Comparison of predictions</span> \n",
    "`A` What is the most striking difference between the predictions across the three ML models? Can you explain this?<br>\n",
    "`B` How would the (ideal) scatter plot look like? I.e. when the model would perfectly predict our target?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE YOUR ANSWERS HERE (Use as many cells as you need)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way the compare the predictions of the three models is by creating a **kernel density plot**. A kernel density plot visualises the distribution, i.e. the probability density, of a variable, in a smooth way, see e.g. [wikipedia.org/wiki/Kernel_density_estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot kernel densities for the test data\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Plot kernel density of the true distribution, i.e of Y_test\n",
    "sns.kdeplot(data = Y_test, ax=ax, legend=True,fill=True,alpha=.3, clip =(0,1), label = 'True')\n",
    "\n",
    "# Plot kernel densities of the predicted distributions, based on the three models\n",
    "sns.kdeplot(data = regr.predict(X_test),ax=ax, legend=True,fill=True,alpha=.3, clip =(0,1), label = f'Regression | R2 = {regr.score(X_test,Y_test):0.3f}')\n",
    "sns.kdeplot(data = dt.predict(X_test),  ax=ax, legend=True,fill=True,alpha=.3, clip =(0,1), label = f'Decision tree | R2 = {dt.score(X_test,Y_test):0.3f}')\n",
    "sns.kdeplot(data = rf.predict(X_test),  ax=ax, legend=True,fill=True,alpha=.3, clip =(0,1), label = f'Random Forest | R2 = {rf.score(X_test,Y_test):0.3f}')\n",
    "\n",
    "# Add legend and title to the plot\n",
    "#ax.legend(['True','Regression model', 'Decision tree','Random Forest'])\n",
    "ax.legend()\n",
    "plt.title('True vs predicted SHARE_HIGH')\n",
    "ax.set_xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Complementarity of the models**\n",
    "- Each model gives us different insights on the relationship explored.\n",
    "- The linear regression model gives a quick overview of the associations between the variable we want to predict and the features we have.\n",
    "- The linear regression mode cannot capture nonlinear relationships without intervention from the analyst: **the size of the school** has a very strong impact on the school performance, but this impact is non-linear, and the regression model underfits. \n",
    "- The decision tree can capture nonlinear relationships, and the analyst can easily interprete the model.\n",
    "- However, the decision tree may overfit (for instance if the maximum tree depth is set to high).\n",
    "- The random forest captures also nonlinear relationships better than the decision tree, but is somehwhat less straightforward to interprete. It reduces the variance of DTs.\n",
    "- Hence, the first two models are useful in the exploratory analysis phase, while the random forest (and similarly flexible machine learning approaches) are especially useful to improve the predicting power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Model development cycle\n",
    "\n",
    "If you have carefully inspected the trees produced by the DT and RF, you might have noticed the first split is (often) based on very small schools: TOTAL_STUDENTS < 11. When we go back to our data we see that this strongly correlates with a categorical feature called `SPECIES_PO` (see left-hand side boxplot below). Unaware of its meaning, at the start of the data exploration of this lab session we too quickly (and erroneaously) discarded this feature as irrelevant. `SPECIES_PO` has two categories: Bo and Sbo. 'Bo' stands for conventional education, while 'Sbo' stands for special education. Sbo schools are schools specifically targeted to cater for students that would not do well in the standard school system and are ussually small. A simple boxplot shows a strong effect of the `SPECIES_PO` on the target feature (see right-hand side plot below). This relationship totally makes sense. With this new insight we are able to improve the models, e.g. include `SPECIES_PO` specification of the linear regression model in a next cycle of the model development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Boxplot SPECIES_PO vs SHARE_HIGH\n",
    "fig, ax = plt.subplots(1,2,figsize =(12,5))\n",
    "sns.boxplot(x='SPECIES_PO', y='TOTAL_STUDENTS', data=df_schools, ax= ax[0])\n",
    "ax[0].set_xticklabels(ax[0].get_xticklabels(),rotation=90)\n",
    "\n",
    "sns.boxplot(x='SPECIES_PO', y='SHARE_HIGH', data=df_schools, ax= ax[1])\n",
    "ax[1].set_xticklabels(ax[1].get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:skyblue\">Exercise 6:   Conclusion and reflection on the results (Discuss with the TAs)</span> \n",
    "In this lab session we have analysed the school data, and made predictions for SHARE_HIGH using three ML models.<br>\n",
    "`A` Based on the above analyses, which of these models can best be used to predict SHARE_HIGH? Explain your answer.<br>\n",
    "`B` In the kernel density plots, we see that the true variance of SHARE_HIGH (in blue) is considerably larger than the variance of SHARE_HIGH predicted by any of the ML models. What does this tell us about this regression problem?<br>\n",
    "`C` Answer RQ1: Is the share of school leavers with an advice for higher education, larger at **large schools** than at **small schools**? Or is it impossible to say?<br>\n",
    "`D` Answer RQ2: Does the type of school (i.e its **denomination**) matters for the share of school leavers with an advice for higher education?  Or is it impossible to say?<br>\n",
    "`E` How has applying multiple ML models helped you to answer the research questions?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE YOUR ANSWERS HERE (Use as many cells as you need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5. Ensemble models**\n",
    "- Ensemble models are combinations of multiple models.\n",
    "- In the cell below, we show how to implement an ensemble model.\n",
    "- That ensemble model is composed of the regression model and decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble objects\n",
    "er = VotingRegressor([('lr', regr), ('dt', dt)])\n",
    "\n",
    "# Fit ensemble objects\n",
    "er.fit(X_train,Y_train)\n",
    "\n",
    "# Evaluate the performance of the ensemble\n",
    "print('Results ensemble')\n",
    "eval_regression_perf(er,X_train, X_test,Y_train,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**<br>\n",
    "* Since the regression model does not perform very well (i.e. without using the SPECIES_PO feature), the ensemble performs worse in this case than the individual DT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit ('tpm34a')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc97a96f317a709ae2c462a7d0437fc605198aec43f9a7dadb54e6d81820938d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
