{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8uT-aSmIU0t"
      },
      "source": [
        "# Lab 4 - Detecting and Mitiating Bias in Machine Learning\n",
        "Week 4 - PM034A Machine learning for socio-technical systems <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1UeTKVmIU0t"
      },
      "source": [
        "By <b> Nadia Metoui* </b> <br>\n",
        "Faculty of Technology, Policy, and Management (TPM)<br>\n",
        "\n",
        "<small>*Acknowledgement: Part of this lab is loosely based on the code developed by <i><b>Agathe Balayn</b></i> and <i><b>Seda Gürses</b></i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKPwVwVyIU0t"
      },
      "source": [
        "***Learning Objectives***<br>\n",
        "Examine the impact of ML-based solutions and interventions on individuals, organisations, and society.<br>\n",
        "Apply ML <b>Operational Fairness tools</b> in real-world socio-technical examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9ydppeIU0u"
      },
      "source": [
        "<H2> </H2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGfHB25Ltha"
      },
      "source": [
        "# Part I. Pre-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6FMhDtrIU0u"
      },
      "source": [
        "In this part of the assignment, you will be exploring a use case where a Bank wants to develop an ML-based ADM (automate decision system) to decide whether to <b>grant</b> or <b>not to grant</b> a loan to a given applicant. To do so the Bank uses historical data containing multiple application records, characterized by information about the loan applicants (e.g., age, gender, personal situation) and information about the loan (e.g., amount, duration, purpose). Each application is labeled <i><b> good credit </b></i> if the loan had been reimbursed or <i><b>bad credit</b></i> if the loan has not been reimbursed or if there where several issues with the reimbursement.\n",
        "\n",
        "To simulate this scenario we will build a classifier to disinguich between good and bad loans (or credits). We will train the classifier using the <i><b>German credit data</b></i> (you can information about the dataset and its attributes here: (https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc).<br>\n",
        "And you can download the dataset here:\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data<br>\n",
        "\n",
        "\n",
        "- Step 1: Set-up (Provided)\n",
        "- Step 2: Explore and familiarize with the dataset\n",
        "- Step 3: Protected attributes, proxies, \n",
        "- Step 4: Representation Bias, Disparities and Skews.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UYkPwm5IU0v"
      },
      "source": [
        "<H3>Setp 1: Set-up</H3>\n",
        "\n",
        "You first need to install the required libraries for this part.  The main libraries are the `aif360` and `sklearn` ones. We also recommend using `numpy` or `pandas` to easily manipulate and explore the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnqQI4-xIU0v"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> Uncomment and run the next cell if you have not previously installed the libraries.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0k-Qw20IU0v"
      },
      "source": [
        "<b>Installing required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4vG8dTvIU0w",
        "outputId": "b153cd1a-11b2-479d-b79a-b261661bd16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aif360\n",
            "  Downloading aif360-0.5.0-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from aif360) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from aif360) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360) (1.4.4)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.8.0-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.1->fairlearn) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.1.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.8.0\n"
          ]
        }
      ],
      "source": [
        "# #uncomment if you need to install the libraries\n",
        "!pip install aif360\n",
        "!pip install fairlearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vShFtuezIU0w"
      },
      "source": [
        "<b>Loading required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiHQY_LCIU0w",
        "outputId": "dcf84335-9c5e-4f8f-f8e9-1026eb1ac295"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
            "pip install 'aif360[LawSchoolGPA]'\n"
          ]
        }
      ],
      "source": [
        "# Libraries for data processing and visualiztion \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "#ML libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Faireness Tool IBM AI Fairness 360\n",
        "from aif360.datasets import GermanDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zF_POAMRd3I"
      },
      "source": [
        "<b>Download the German Credit Data set</b><br>\n",
        "In the following we will download the data set and https://archive.ics.uci.edu its documentation from the website and place it in the correct folder to be accessed by aif360."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GWW3vXKSo6Z"
      },
      "source": [
        "**Option 1 Google Colab:**<br>\n",
        "Uncomment the following cell to download the dataset in google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mcNotjsPyjZ",
        "outputId": "3f76b8bf-b2a1-44eb-c5c8-74bd32df00c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-07 16:10:19--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79793 (78K) [application/x-httpd-php]\n",
            "Saving to: ‘german.data’\n",
            "\n",
            "german.data         100%[===================>]  77.92K   488KB/s    in 0.2s    \n",
            "\n",
            "2022-12-07 16:10:20 (488 KB/s) - ‘german.data’ saved [79793/79793]\n",
            "\n",
            "--2022-12-07 16:10:20--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4679 (4.6K) [application/x-httpd-php]\n",
            "Saving to: ‘german.doc’\n",
            "\n",
            "german.doc          100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-07 16:10:20 (96.7 MB/s) - ‘german.doc’ saved [4679/4679]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Download the German Credit DataSet\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
        "!cp german.data /usr/local/lib/python3.8/dist-packages/aif360/data/raw/german/german.data\n",
        "!cp german.doc /usr/local/lib/python3.8/dist-packages/aif360/data/raw/german/german.doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCKBANQFSY_G"
      },
      "source": [
        "**Option 2: Local environment**<br>\n",
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> If you are working on your local environment you will have to manually add the files \"german.doc\" and \"german.data\" to the folder \n",
        "\"dist-packages/aif360/data/raw/german/\" under your python path.<br>\n",
        "You can find the files in the lab folder on github or download them from: <br>\n",
        "<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\">https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data</a> <br>\n",
        "<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\">https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc</a>\n",
        "</div> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S7flKyCIU0x"
      },
      "source": [
        "<b>Loading the dataset</b>\n",
        "\n",
        "Here, we will load the <i><b>German credit data</b></i> in a format that is compatible with the use of the <i><b>AIF360 toolkit</b></i>. For this, you need to make use of the already implemented class of the toolkit `GermanDataset()`.\n",
        "\n",
        "Because the data available is encoded in a complex way, we provide you with the code to preprocess it, in the function `custom_preprocessing()`. We also provide you with an example on how to actually load the data using the `GermanDataset()` class, in `preproc_and_load_data_german()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ViJlrVIzIU0x"
      },
      "outputs": [],
      "source": [
        "def preproc_and_load_data_german():\n",
        "    \"\"\"\n",
        "    Load and pre-process german credit dataset.\n",
        "    Args: -\n",
        "    Returns:\n",
        "        GermanDataset: An instance of GermanDataset with required pre-processing.\n",
        "    \"\"\"\n",
        "    def custom_preprocessing(df):\n",
        "        \"\"\" Custom pre-processing for German Credit Data\n",
        "        \"\"\"\n",
        "\n",
        "        def group_credit_hist(x):\n",
        "            if x in ['A30', 'A31', 'A32']:\n",
        "                return 'None/Paid'\n",
        "            elif x == 'A33':\n",
        "                return 'Delay'\n",
        "            elif x == 'A34':\n",
        "                return 'Other'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_employ(x):\n",
        "            if x == 'A71':\n",
        "                return 'Unemployed'\n",
        "            elif x in ['A72', 'A73']:\n",
        "                return '1-4 years'\n",
        "            elif x in ['A74', 'A75']:\n",
        "                return '4+ years'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_savings(x):\n",
        "            if x in ['A61', 'A62']:\n",
        "                return '<500'\n",
        "            elif x in ['A63', 'A64']:\n",
        "                return '500+'\n",
        "            elif x == 'A65':\n",
        "                return 'Unknown/None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_status(x):\n",
        "            if x in ['A11', 'A12']:\n",
        "                return '<200'\n",
        "            elif x in ['A13']:\n",
        "                return '200+'\n",
        "            elif x == 'A14':\n",
        "                return 'None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "        \n",
        "        def group_personal_status(x):\n",
        "            if x in ['A91']:\n",
        "                return 'divorced/separated'\n",
        "            elif x in ['A92']:\n",
        "                return 'divorced/separated/married'\n",
        "            elif x in ['A93', 'A95']:\n",
        "                return 'single'\n",
        "            elif x in ['A94']:\n",
        "                return 'married/widowed'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_foreign_worker(x):\n",
        "            if x in ['A201']:\n",
        "                return 'yes'\n",
        "            elif x in ['A202']:\n",
        "                return 'no'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        #print(df)\n",
        "        #print(df.shape)\n",
        "        #print(df.isnull().sum().sum())\n",
        "        #print(df.isin(['NA']).sum(axis=0))\n",
        "        status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n",
        "                    'A92': 0.0, 'A95': 0.0}\n",
        "        \n",
        "        df['sex'] = df['personal_status'].replace(status_map)\n",
        "        \n",
        "\n",
        "        # group credit history, savings, and employment\n",
        "        df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
        "        df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
        "        df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
        "        #df['age'] = df['age'].apply(lambda x: np.float(x >= 26))\n",
        "        df['status'] = df['status'].apply(lambda x: group_status(x))\n",
        "        df['personal_status'] = df['personal_status'].apply(lambda x: group_personal_status(x))\n",
        "        df['foreign_worker'] = df['foreign_worker'].apply(lambda x: group_foreign_worker(x))\n",
        "        group_foreign_worker\n",
        "        #print(df.isin(['NA']).sum(axis=0))\n",
        "        \n",
        "        # print(df)\n",
        "        # uncomment if you want to save a version of the processed data\n",
        "        #df.to_csv(\"german_credit_data_processed.csv\")\n",
        "        return df\n",
        "\n",
        "    # Feature partitions\n",
        "    XD_features = ['number_of_credits', 'telephone',\n",
        "                     'foreign_worker', 'people_liable_for', 'skill_level', 'credit_history', 'installment_plans', 'residence_since', 'property', 'other_debtors', 'purpose', 'savings', 'employment', 'sex', 'age', 'personal_status', 'month']\n",
        "    D_features = ['sex', 'age'] \n",
        "    Y_features = ['credit']\n",
        "    X_features = list(set(XD_features)-set(D_features))\n",
        "    categorical_features = ['installment_plans', 'telephone',\n",
        "                     'foreign_worker', 'skill_level', 'credit_history', 'property', \n",
        "                            'other_debtors', 'purpose', 'savings', 'employment', 'personal_status']\n",
        "\n",
        "    # privileged classes\n",
        "    all_privileged_classes = {\"sex\": [1.0],\n",
        "                              \"age\": lambda x: x > 25}\n",
        "\n",
        "    # protected attribute maps\n",
        "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
        "                                    \"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
        "\n",
        "    return GermanDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=[1],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        features_to_drop=[],\n",
        "        metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
        "                   'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHjx1gHqIU0x"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuETGJnvIU0x"
      },
      "source": [
        "<H3>Step 2: Explore and familiarize with the dataset</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72qzba_IU0x"
      },
      "source": [
        "<b>Q1: Analyse the dataset and answer the following:</b> \n",
        "- What is the number of records?\n",
        "- What is the number of attributes present with the preprocessing we provided? \n",
        "- What is the list of attribute names?\n",
        "- Are there missing values that could create biases?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TZcHsBxZIU0y"
      },
      "outputs": [],
      "source": [
        "# Instanciating the German credit dataset\n",
        "dataset_gcredit = preproc_and_load_data_german()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-QweV_hIU0y"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> The documentation of \"AIF360 - German credit data\" dataset  can be found <a href=\"https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.GermanDataset.html\">[HERE]</a>. </div> \n",
        "\n",
        "\n",
        "Take a look at documentation of AIF360 and use existing methods to explore the dataset instance how to access the features with:<br> `dataset_gcredit.features`. \n",
        "\n",
        "You are also free to transform the dataset into a pandas dataframe to extract the needed information.\n",
        "Use <br>\n",
        "    `pd_gdata = pd.DataFrame(dataset_gcredit.features, columns=dataset_gcredit.feature_names)` <br>\n",
        "    to create the pandas dataframe\n",
        "</div> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnL3_NqTIU0y"
      },
      "source": [
        "- "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GOTIV9caIU0y"
      },
      "outputs": [],
      "source": [
        "### Some possible explorations ###\n",
        "# Number of records:\n",
        "\n",
        "# Number of features:\n",
        "\n",
        "# Feature names:\n",
        "\n",
        "# Number of missing values for each attribute ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAR80f9aIU0y"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wjER9PIIU0y"
      },
      "source": [
        "<H3>Step 3: Pre-processing: Protected attributes, proxies.</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ0KNLNyIU0y"
      },
      "source": [
        "<b>Q2: Identification of protected attributes</b>\n",
        "\n",
        "a) Study the dataset and its documentation and identify which attributes that might raise unfairness concerns and should be considered protected (according to the law). Explain, in your opinion, why are these attributes protected provide exaples of bias or unfaireness for each identified attribute. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD7Px03DIU0y"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> \n",
        "\n",
        "Take a look at the following documents<br>\n",
        "<a href=\"https://www.equalityhumanrights.com/en/equality-act/protected-characteristics\">(1) \n",
        "Protected characteristics | Equality and Human Rights Commission (UK, 2021)</a><br>\n",
        "<a href=\"https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73\">(2) Discrimination, Artificial Intelligence, and Algorithmic Decision-Making (2018)</a><br>\n",
        "<a href=\"http://ec.europa.eu/social/BlobServlet?docId=1691&langId=en&usg=AOvVaw3vI30bO3jisairH2Z7-nSl\">(3) Age discrimination and European Law (2005)</a>. \n",
        "<div> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byYv9J9HIU0y"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgsZ4jJNIU0z"
      },
      "source": [
        "b) Study the dataset and its documentation and identify any further \"non-protect\" attributes that could cause  unfairenesses. Explain your reasoning. provide examples of bias or unfairenesse related to each attribut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hv8Ld7dIU0z"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyQV4CWdIU0z"
      },
      "source": [
        "<b>Q3:  Identification of \"spurious\" proxies </b>\n",
        "\n",
        "a) Find the proxies for the attribute \"sex\".\n",
        "\n",
        "b) Find proxies for one additional protected attribut you identified in Q2-a.\n",
        "\n",
        "c) In your opinion, why do we want to identify proxies for protected attributes in a dataset? How should you handle the proxies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPwXsAYiIU0z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b>A proxy attribute <i>Ap</i>  is an attribute that has a similar distribution as another attribute <i>Ax</i>, so having access to the proxy attribute <i>Ap</i> provides a good knowledge of the other attribute <i>Ax</i>. For instance, in the US the zipcode is a powerful proxy for race and education, the zipcode combined with websites visited is an even more powerful proxy, names in certain languages are strong proxies for gender, etc.<br>\n",
        "\n",
        "The simplest way to identify proxy attributes for a protected attribute <i>Ax</i> is to compute the correlation of <i>Ax</i>  with each other attributes in the dataset. The higher the corrolation (absolute value of the corrolation) the higher the likelihood an attribute is a proxy of <i>Ax</i> <br>\n",
        "\n",
        "You can use the `corr()` function of the pandas library to compute the correlation between two attributes\n",
        "</div> \n",
        "\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB5dyQMz0iy2"
      },
      "source": [
        "<H3>Step 4: Representation Bias, Disparities and Skews.</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrmBjYfQIU0z"
      },
      "source": [
        "<br>\n",
        "<b>Q4: Representation biases: Representation Disparity</b>\n",
        "\n",
        "a) Is the dataset we are working with representative of the German population with regard to age. Add any needed code or analysis to briefely justify your answer<br>\n",
        "b) Is the dataset we are working with representative of the German population with regard to gender. Add any needed code or analysis to briefely justify your answer\n",
        "\n",
        "<b>(Optional)</b><br>\n",
        "c) Look at the joint distribution of the attributes for sex and personal_status=divorced/separated/married. Does the dataset seem to be representative of the German population?<br>\n",
        "d) Similarly, look at the distribution of foreign workers. Does the dataset seem to be representative of the German population?<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcEkGsg5IU0z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> You can find demographic information from Wikipedia <a href=https://en.wikipedia.org/wiki/Demographics_of_Germany>[Here]</a>\n",
        "    \n",
        "Go to section <b><i>Demographic statistics</i></b> take a closer look at the most racent  <b><i>Age structure</i></b> data (it should be from 2018). Use this data to build a distribution of german population across age, then across gender and compare it to the distributions from <b><i>the German credit data</i></b> we are working with.\n",
        "\n",
        "It is up to you how you want to justify your answer, however using visualizations will provide more points (i.e., plots and diagram)\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rYvNpGAjIU0z"
      },
      "outputs": [],
      "source": [
        "# write you code here \n",
        "# \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ecLni1PIU0z"
      },
      "source": [
        "Don't forget to analyse your findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KiN6t-HIU0z"
      },
      "source": [
        "<b>Q5: Representation Bias: Outcome Skews </b> \n",
        "\n",
        "Is there a skew towards certain groups:<br>\n",
        "a) Analyse the dataset, and report the numbers of male / female with bad/good credit. Do the same for \"old\" / \" young\" people in the datset. Normalize these numbers respectively over the total number of male/female, \"old\"/\"young\" for a fair comparison. For that, you can consider having 50 individuals for each of these groups.\n",
        "\n",
        "b) Brieflt describe your findings and explain the impacts (on faireness) of using this dataset as training data (if any)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-JA8YQXIU0z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> We provide a function for Normalised count per attribut and lable you are free to use it or implement your own method \n",
        "    \n",
        "`getNormalizedCount(pd_train_data, protected_attribute, label)`\n",
        "</div>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sa1TYykRIU0z"
      },
      "outputs": [],
      "source": [
        "# Normalised count per attribut and lable \n",
        "def getNormalizedCount(pd_train_data, protected_attribute, label):\n",
        "    unnormalized_count = pd_train_data[[protected_attribute, label]].value_counts()\n",
        "    counts = {}\n",
        "    for attribute_value in pd_train_data[[protected_attribute]].value_counts().keys():\n",
        "        counts[attribute_value[0]] = pd_train_data[[protected_attribute]].value_counts()[attribute_value]\n",
        "    normalized_count = unnormalized_count[:]\n",
        "    for attribute_value, credit_value in pd_train_data[[protected_attribute, label]].value_counts().keys():\n",
        "        normalized_count[attribute_value, credit_value] = normalized_count[attribute_value, credit_value] * (50 / counts[attribute_value])\n",
        "    return normalized_count\n",
        "\n",
        "# add the credit labels to the data set.\n",
        "pd_gdata[\"credit\"] = dataset_gcredit.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VEBa9CquIU00"
      },
      "outputs": [],
      "source": [
        "### YOUR ANSWER HERE ###\n",
        "# ADD code here to print the AGE-CREDIT distribution\n",
        "\n",
        "\n",
        "# ADD code here to print the SEX-CREDIT distribution\n",
        "\n",
        "\n",
        "# ADD code here to visualise the results for both you can use stacked bar plots from pandas toolkit\n",
        "#<your dataframe>.size().unstack().plot(kind='bar', stacked=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w6LFn_TIU00"
      },
      "source": [
        "Don't forget to analyse your findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54WeKpG7IU00"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38bW5fATIU00"
      },
      "source": [
        "# Part II. Observational Faireness Metrics.\n",
        "\n",
        "\n",
        "\n",
        "Step 1: Re-process the data. <br>\n",
        "Step 2: Building a Classifier. <br>\n",
        "Step 3: Step 3: Classification threshold and fairness constraint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLQ3fA1a2w6K"
      },
      "source": [
        "<H3>Step 1: Re-process the data.<H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFCt5SW16i3O"
      },
      "source": [
        "**Option 1: Re-process the data for age fairness**<br>\n",
        "uncomment the following block to re-process the data and set age as a protected attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzdMiXcA4ch7"
      },
      "outputs": [],
      "source": [
        "# def preproc_and_load_data_german():\n",
        "#     \"\"\"\n",
        "#     Load and pre-process german credit dataset.\n",
        "#     Args: -\n",
        "#     Returns:\n",
        "#         GermanDataset: An instance of GermanDataset with required pre-processing.\n",
        "#     \"\"\"\n",
        "#     def custom_preprocessing(df):\n",
        "#         \"\"\" Custom pre-processing for German Credit Data\n",
        "#         \"\"\"\n",
        "\n",
        "#         def group_credit_hist(x):\n",
        "#             if x in ['A30', 'A31', 'A32']:\n",
        "#                 return 'None/Paid'\n",
        "#             elif x == 'A33':\n",
        "#                 return 'Delay'\n",
        "#             elif x == 'A34':\n",
        "#                 return 'Other'\n",
        "#             else:\n",
        "#                 return 'NA'\n",
        "\n",
        "#         def group_employ(x):\n",
        "#             if x == 'A71':\n",
        "#                 return 'Unemployed'\n",
        "#             elif x in ['A72', 'A73']:\n",
        "#                 return '1-4 years'\n",
        "#             elif x in ['A74', 'A75']:\n",
        "#                 return '4+ years'\n",
        "#             else:\n",
        "#                 return 'NA'\n",
        "\n",
        "#         def group_savings(x):\n",
        "#             if x in ['A61', 'A62']:\n",
        "#                 return '<500'\n",
        "#             elif x in ['A63', 'A64']:\n",
        "#                 return '500+'\n",
        "#             elif x == 'A65':\n",
        "#                 return 'Unknown/None'\n",
        "#             else:\n",
        "#                 return 'NA'\n",
        "\n",
        "#         def group_status(x):\n",
        "#             if x in ['A11', 'A12']:\n",
        "#                 return '<200'\n",
        "#             elif x in ['A13']:\n",
        "#                 return '200+'\n",
        "#             elif x == 'A14':\n",
        "#                 return 'None'\n",
        "#             else:\n",
        "#                 return 'NA'\n",
        "        \n",
        "#         def group_personal_status(x):\n",
        "#             if x in ['A91']:\n",
        "#                 return 'divorced/separated'\n",
        "#             elif x in ['A92']:\n",
        "#                 return 'divorced/separated/married'\n",
        "#             elif x in ['A93', 'A95']:\n",
        "#                 return 'single'\n",
        "#             elif x in ['A94']:\n",
        "#                 return 'married/widowed'\n",
        "#             else:\n",
        "#                 return 'NA'\n",
        "\n",
        "#         def group_foreign_worker(x):\n",
        "#             if x in ['A201']:\n",
        "#                 return 'yes'\n",
        "#             elif x in ['A202']:\n",
        "#                 return 'no'\n",
        "#             else:\n",
        "#                 return 'NA'\n",
        "\n",
        "#         #print(df)\n",
        "#         #print(df.shape)\n",
        "#         #print(df.isnull().sum().sum())\n",
        "#         #print(df.isin(['NA']).sum(axis=0))\n",
        "#         status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n",
        "#                     'A92': 0.0, 'A95': 0.0}\n",
        "        \n",
        "#         df['sex'] = df['personal_status'].replace(status_map)\n",
        "        \n",
        "\n",
        "#         # group credit history, savings, and employment\n",
        "#         df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
        "#         df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
        "#         df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
        "#         #df['age'] = df['age'].apply(lambda x: np.float(x >= 26))\n",
        "#         df['status'] = df['status'].apply(lambda x: group_status(x))\n",
        "#         df['personal_status'] = df['personal_status'].apply(lambda x: group_personal_status(x))\n",
        "#         df['foreign_worker'] = df['foreign_worker'].apply(lambda x: group_foreign_worker(x))\n",
        "#         group_foreign_worker\n",
        "#         #print(df.isin(['NA']).sum(axis=0))\n",
        "        \n",
        "#         # print(df)\n",
        "#         # uncomment if you want to save a version of the processed data\n",
        "#         #df.to_csv(\"german_credit_data_processed.csv\")\n",
        "#         return df\n",
        "\n",
        "#     # Feature partitions\n",
        "#     XD_features = ['number_of_credits', 'telephone',\n",
        "#                      'foreign_worker', 'people_liable_for', 'skill_level', 'credit_history',\\\n",
        "#                    'installment_plans', 'residence_since', 'property', 'other_debtors', \\\n",
        "#                    'purpose', 'savings', 'employment', 'sex', 'age', 'month']\n",
        "#     D_features = ['age'] \n",
        "#     Y_features = ['credit']\n",
        "#     X_features = list(set(XD_features)-set(D_features))\n",
        "#     categorical_features = ['installment_plans', 'telephone',\n",
        "#                      'foreign_worker', 'skill_level', 'credit_history', 'property',\\\n",
        "#                             'other_debtors', 'purpose', 'savings', 'employment']\n",
        "\n",
        "#     # privileged classes\n",
        "#     all_privileged_classes = {\"age\": lambda x: x > 25}\n",
        "\n",
        "#     # protected attribute maps\n",
        "#     all_protected_attribute_maps = {\"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
        "\n",
        "#     return GermanDataset(\n",
        "#         label_name=Y_features[0],\n",
        "#         favorable_classes=[1],\n",
        "#         protected_attribute_names=D_features,\n",
        "#         privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "#         instance_weights_name=None,\n",
        "#         categorical_features=categorical_features,\n",
        "#         features_to_keep=X_features+Y_features+D_features,\n",
        "#         features_to_drop=[\"sex\", \"personal_status=divorced/separated/married\"],\n",
        "#         metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
        "#                    'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "#                                 for x in D_features]},\n",
        "#         custom_preprocessing=custom_preprocessing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8YWLe7uIDGl"
      },
      "outputs": [],
      "source": [
        "# dataset_orig = preproc_and_load_data_german()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzpP0xCOIU00"
      },
      "source": [
        "<b>Q6: Option 1</b>\n",
        "\n",
        "a) Set the privilege and unprivilaged age group based on the findings of question Q5-a (answer in the text then add the variables 0 or 1 to the code below). Provide a very brief justification for your answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iSmBHBRIU00"
      },
      "outputs": [],
      "source": [
        "# Add the code for question a) here\n",
        "# code = 1: is old above 25\n",
        "# code = 0: is young under 25\n",
        "\n",
        "#privileged_code = #add the write code here\n",
        "#unprivileged_code = #add the write code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm9fW-WgIU00"
      },
      "outputs": [],
      "source": [
        "# # We start by defining the privilaged and unprivileged \n",
        "# privileged_groups = [{'age': privileged_code}] \n",
        "# unprivileged_groups = [{'age': unprivileged_code}] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hSdUv7h_QM"
      },
      "source": [
        "**Option 2: Re-process the data for gender fairness**<br>\n",
        "uncomment the following block to re-process the data and set sex as a protected attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJEHwH4_hv7k"
      },
      "outputs": [],
      "source": [
        "def preproc_and_load_data_german():\n",
        "    \"\"\"\n",
        "    Load and pre-process german credit dataset.\n",
        "    Args: -\n",
        "    Returns:\n",
        "        GermanDataset: An instance of GermanDataset with required pre-processing.\n",
        "    \"\"\"\n",
        "    def custom_preprocessing(df):\n",
        "        \"\"\" Custom pre-processing for German Credit Data\n",
        "        \"\"\"\n",
        "\n",
        "        def group_credit_hist(x):\n",
        "            if x in ['A30', 'A31', 'A32']:\n",
        "                return 'None/Paid'\n",
        "            elif x == 'A33':\n",
        "                return 'Delay'\n",
        "            elif x == 'A34':\n",
        "                return 'Other'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_employ(x):\n",
        "            if x == 'A71':\n",
        "                return 'Unemployed'\n",
        "            elif x in ['A72', 'A73']:\n",
        "                return '1-4 years'\n",
        "            elif x in ['A74', 'A75']:\n",
        "                return '4+ years'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_savings(x):\n",
        "            if x in ['A61', 'A62']:\n",
        "                return '<500'\n",
        "            elif x in ['A63', 'A64']:\n",
        "                return '500+'\n",
        "            elif x == 'A65':\n",
        "                return 'Unknown/None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        def group_status(x):\n",
        "            if x in ['A11', 'A12']:\n",
        "                return '<200'\n",
        "            elif x in ['A13']:\n",
        "                return '200+'\n",
        "            elif x == 'A14':\n",
        "                return 'None'\n",
        "            else:\n",
        "                return 'NA'\n",
        "        \n",
        "        def group_personal_status(x):\n",
        "            if x in ['A91']:\n",
        "                return 'divorced/separated'\n",
        "            elif x in ['A92']:\n",
        "                return 'divorced/separated/married'\n",
        "            elif x in ['A93', 'A95']:\n",
        "                return 'single'\n",
        "            elif x in ['A94']:\n",
        "                return 'married/widowed'\n",
        "            else:\n",
        "                return 'NA'\n",
        "\n",
        "        status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n",
        "                    'A92': 0.0, 'A95': 0.0}\n",
        "        \n",
        "        df['sex'] = df['personal_status'].replace(status_map)\n",
        "        \n",
        "\n",
        "        # group credit history, savings, and employment\n",
        "        df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
        "        df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
        "        df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
        "        #df['age'] = df['age'].apply(lambda x: np.float(x >= 26))\n",
        "        df['status'] = df['status'].apply(lambda x: group_status(x))\n",
        "        df['personal_status'] = df['personal_status'].apply(lambda x: group_personal_status(x))\n",
        "        \n",
        "        return df\n",
        "\n",
        "    # Feature partitions\n",
        "    XD_features = ['number_of_credits', 'telephone',\n",
        "                     'foreign_worker', 'people_liable_for', 'skill_level', 'credit_history',\\\n",
        "                   'installment_plans', 'residence_since', 'property', 'other_debtors', \\\n",
        "                   'purpose', 'savings', 'employment', 'sex', 'age', 'month']\n",
        "    D_features = ['sex'] \n",
        "    Y_features = ['credit']\n",
        "    X_features = list(set(XD_features)-set(D_features))\n",
        "    categorical_features = ['installment_plans', 'telephone',\n",
        "                     'foreign_worker', 'skill_level', 'credit_history', 'property',\\\n",
        "                            'other_debtors', 'purpose', 'savings', 'employment']\n",
        "\n",
        "    # privileged classes\n",
        "    all_privileged_classes = {\"sex\": [1.0]}\n",
        "\n",
        "    # protected attribute maps\n",
        "    all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'}}\n",
        "\n",
        "    return GermanDataset(\n",
        "        label_name=Y_features[0],\n",
        "        favorable_classes=[1],\n",
        "        protected_attribute_names=D_features,\n",
        "        privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
        "        instance_weights_name=None,\n",
        "        categorical_features=categorical_features,\n",
        "        features_to_keep=X_features+Y_features+D_features,\n",
        "        features_to_drop=[],\n",
        "        metadata={ 'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
        "                   'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
        "                                for x in D_features]},\n",
        "        custom_preprocessing=custom_preprocessing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35RqaImoiel_"
      },
      "outputs": [],
      "source": [
        "dataset_orig = preproc_and_load_data_german()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwF8Ags3iel-"
      },
      "source": [
        "<b>Q6: Option 2</b>\n",
        "\n",
        "a) Set the privilege and unprivilaged age group based on the findings of question Q5-a (answer in the text then add the variables 0 or 1 to the code below). Provide a very brief justification for your answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYOLBtELiel_"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rse0aEgdiel_"
      },
      "outputs": [],
      "source": [
        "# Add the code for question a) here\n",
        "# code = 1: male\n",
        "# code = 0: female\n",
        "\n",
        "#privileged_code = #add the write code here\n",
        "#unprivileged_code = #add the write code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mzihOUciel_"
      },
      "outputs": [],
      "source": [
        "# # We start by defining the privilaged and unprivileged \n",
        "privileged_groups = [{'sex': privileged_code}]\n",
        "unprivileged_groups = [{'sex': unprivileged_code}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJjFKXaP9wJP"
      },
      "source": [
        "#### Preparation for training a classifier.\n",
        "As we will learn a classifier, we need to divide the data into a training, validation and test sets.\n",
        "We define them to use respectively 60%, 20% and 20% of the whole data.\n",
        "We will use the following code to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf8EX8yWIU00"
      },
      "outputs": [],
      "source": [
        "dataset_orig_train, dataset_orig_val, dataset_orig_test = \\\n",
        "    dataset_orig.split([0.6, 0.8], shuffle=True, seed=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd1cpjrOIKf5"
      },
      "source": [
        "#### Training a classifier.\n",
        "As we want to automate the decision process, we need to learn a classifier. We make the choice of using a logistic regression classifier, that we train with the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk3PI0ivIJtM"
      },
      "outputs": [],
      "source": [
        "model = make_pipeline(StandardScaler(),\n",
        "                      LogisticRegression(solver='liblinear', random_state=1))\n",
        "fit_params = {'logisticregression__sample_weight': dataset_orig_train.instance_weights}\n",
        "\n",
        "lr_orig = model.fit(dataset_orig_train.features, dataset_orig_train.labels.ravel(), **fit_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lp8lZJnIw49"
      },
      "source": [
        "#### Q7: Decision threshold and accuracy\n",
        "#### *Determine the decision threshold to use for this logistic regression classifier, explain your method and report the threshold. Then, report the test accuracy and this average score for the test set for this threshold.* \n",
        "*Hint: Because this dataset might be class imbalanced, instead of using the accuracy, you should use the average of the true positive and true negative ratios.*\n",
        "\n",
        "*Hint: We provide you with the \"test()\" function in order to compute various metrics on a dataset, for different thresholds. You can instantiate these thresholds with \"thresh_arr = np.linspace(0.01, 0.99, 100)\".*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "selsPBiZI1kU"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def test(dataset, model, thresh_arr):\n",
        "    dataset_pred = dataset.copy(deepcopy=True)\n",
        "    pos_ind = np.where(model.classes_ == dataset.favorable_label)[0][0]\n",
        "    dataset_pred.scores = model.predict_proba(dataset_pred.features)[:,pos_ind].reshape(-1,1)\n",
        "    \n",
        "    metric_arrs = defaultdict(list)\n",
        "    for thresh in thresh_arr:\n",
        "        fav_inds = dataset_pred.scores > thresh\n",
        "        dataset_pred.labels[fav_inds] = dataset_pred.favorable_label\n",
        "        dataset_pred.labels[~fav_inds] = dataset_pred.unfavorable_label\n",
        "\n",
        "        # Computation of various metrics:\n",
        "        metric = ClassificationMetric(\n",
        "                dataset, dataset_pred,\n",
        "                unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "        metric_arrs['acc'].append(metric.accuracy())\n",
        "        metric_arrs['bal_acc'].append((metric.true_positive_rate()\n",
        "                                     + metric.true_negative_rate()) / 2)\n",
        "        metric_arrs['avg_odds_diff'].append(metric.average_odds_difference())\n",
        "        metric_arrs['disp_imp'].append(metric.disparate_impact())\n",
        "        metric_arrs['stat_par_diff'].append(metric.statistical_parity_difference())\n",
        "        metric_arrs['eq_opp_diff'].append(metric.equal_opportunity_difference())\n",
        "        metric_arrs['theil_ind'].append(metric.theil_index())\n",
        "        metric_arrs['precision_prot'].append(metric.precision(False))\n",
        "        metric_arrs['precision_unprot'].append(metric.precision(True))\n",
        "        metric_arrs['recall_prot'].append(metric.recall(False))\n",
        "        metric_arrs['recall_unprot'].append(metric.recall(True))\n",
        "        metric_arrs['num_TP'].append(metric.num_true_positives())\n",
        "        metric_arrs['num_FP'].append(metric.num_false_positives())\n",
        "        metric_arrs['num_TN'].append(metric.num_true_negatives())\n",
        "        metric_arrs['num_FN'].append(metric.num_false_negatives())\n",
        "        metric_arrs['positive_predictive_value_prot'].append(metric.positive_predictive_value(False))\n",
        "        metric_arrs['positive_predictive_value_unprot'].append(metric.positive_predictive_value(True))\n",
        "        metric_arrs['negative_predictive_value_prot'].append(metric.negative_predictive_value(False))\n",
        "        metric_arrs['negative_predictive_value_unprot'].append(metric.negative_predictive_value(True))\n",
        "        metric_arrs['false_negative_rate_difference'].append(metric.false_negative_rate_difference())\n",
        "        metric_arrs['false_positive_rate_difference'].append(metric.false_positive_rate_difference())\n",
        "        metric_arrs['disparate_impact'].append(metric.disparate_impact())\n",
        "        metric_arrs['statistical_parity_difference'].append(metric.statistical_parity_difference())\n",
        "        \n",
        "        metric_arrs['proba_positive_prot'].append(metric.num_pred_positives(True)/metric.num_instances(True))\n",
        "        metric_arrs['proba_positive_unprot'].append(metric.num_pred_positives(False)/metric.num_instances(False))\n",
        "\n",
        "        metric_arrs['manual_statistical_parity_difference'].append(metric.num_pred_positives(False)/metric.num_instances(False)-metric.num_pred_positives(True)/metric.num_instances(True))\n",
        "        metric_arrs['manual_disparate_impact'].append((metric.num_pred_positives(False)/metric.num_instances(False)) / (metric.num_pred_positives(True)/metric.num_instances(True)))\n",
        "    return metric_arrs\n",
        "\n",
        "thresh_arr = np.linspace(0.01, 0.99, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6wdDHRfJEx6"
      },
      "outputs": [],
      "source": [
        "# Code for Q7:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOq-dJlqMh_J"
      },
      "source": [
        "Take a minut to observe the results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcbVUoqnKLfz"
      },
      "source": [
        "#### Q8: *Confusion matrix*\n",
        "The confusion matrix for this problem looks like the following:\n",
        "\n",
        "    repay        | TP                     | FN\n",
        "\n",
        "    did not repay | FP                     | TN\n",
        "\n",
        "                  | good credit (low risk) | bad credit (high risk)\n",
        "                      \n",
        "#### *a) Give the number of true positive (TP), true negative (TN), false positive (FP) and false negative (FN) for the test set and a threshold of  0.68. Hint: you can use the AIF360 ClassificationMetric class to get these numbers, or make use of certain outputs of the \"test()\" function.*\n",
        "\n",
        "\n",
        "**Optional**\n",
        "Different stakeholders related to the system might want to check that different scores hold, and these scores can be expressed with the numbers in the confusion matrix. That is what we study in the following questions.\n",
        "\n",
        "#### *b) The bank which gives loan might want to check the likelihood for those who are classified as good credit by the system (i.e. those who will be granted a loan), how many will indeed repay. How would you express this ratio in terms of TP, FP, FN, TN? Compute it.*\n",
        "\n",
        "#### *c) The bank might also want to know out of those labeled bad credit, how many would actually repay. How would you express this ratio in terms of TP, FP, FN, TN? Compute it.*\n",
        "\n",
        "#### *d) A bank client would like to know the probability that he/she would be incorrectly classified high risk while they are not. How would you express this ratio in terms of TP, FP, FN, TN? Compute it.*\n",
        "\n",
        "#### *e) A classifier is often evaluated in terms of precision and recall. Compute the two scores. Reminder: precision is expressed in terms of TP / (TP + FP), recall is expressed in terms of TP / (TP + FN). To what extent are these scores satisfying?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjdEKsdtKMB8"
      },
      "outputs": [],
      "source": [
        "# Code for Q8 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDjFUQdMK22o"
      },
      "source": [
        "### Q9: Fairness metrics\n",
        "\n",
        "In Q8, we evaluated the classifer as it is usually done in machine learning. It appears more or less satisfying depending on the metric. But what happens if we now evaluate the classifier separately for the protected and non-protected groups? Reminder: In all the following questions, the protected group will be female, and the non-protected group male.\n",
        "\n",
        "Most group fairness metrics consist in (1) computing one or several of these scores  (and their average) separately for the protected and non protected groups, and then (2) computing the difference or ratio of these scores. In this paper, you can find a summary of the main fairness metrics that exist https://fairware.cs.umass.edu/papers/Verma.pdf.\n",
        "\n",
        "We now take a look at some of these metrics. Hint: for these questions, you can either again make use of the outputs of the \"test()\" function, or draw the confusion matrices for the two groups separately and compute them manually.\n",
        "\n",
        "#### *a) We are interested in the positive predictive value ( TP / (TP + FP)). Compute the difference between the one for the protected group and non-protected group. Provide an interpretation of this metric.*\n",
        "\n",
        "#### *b) We are interested in the negative predictive value ( FN / (FN + TN)). Compute the difference between the one for the protected group and non-protected group. Provide an interpretation of this metric.*\n",
        "\n",
        "#### *c) We are interested in one of the error rate balance measures, relying on false negatives ( FN / (TP + FN)). Compute the difference between the one for the protected group and non-protected group. Provide an interpretation of this metric.*\n",
        "\n",
        "#### *d) We are interested in one of the error rate balance measures, relying on false positives ( FP / (TN + FP)). Compute the difference between the one for the protected group and non-protected group. Provide an interpretation of this metric, especially in comparison with the metric in c).*\n",
        "\n",
        "Disparate impact and statistical parity difference are two other very connected fairness metrics, relying on the probabilities of getting a positive outcome (i.e. getting a good credit label in our scenario) for the protected and non-protected groups. Disparate impact is computed by calculating the ratio of these two numbers, while statistical parity difference consists in computing their difference.\n",
        "#### *e) Provide the measure for these two scores, explain how they relate to the confusion matrix (how are they computed) and explain how you would interpret them, especially in which cases someone might choose to focus on these metrics.*\n",
        "\n",
        "#### *f) Looking at this new information compared to Q8, would you use the classifier in practice? why?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbRNHg-8K2Mt"
      },
      "outputs": [],
      "source": [
        "# Q9  code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxU_SpyULyYc"
      },
      "source": [
        "Answers Q9 Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88IHxAHbR05R"
      },
      "source": [
        "<H3>Step 3: Classification threshold and fairness constraint</H3>\n",
        "The choice of decision threshold does not only impact measures of accuracy, but can also impact the fairness of the classifier. That is what we study here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKk-r1klNGQs"
      },
      "source": [
        "\n",
        "#### Q10: Disparate impact\n",
        "Ideally, the disparate impact is equal to 1, and it can take values above and under 1. The value is lower than 1 when it advantages the non protected group, and above 1 when it advantages the protected one. Because of that, we can not directly compare it to a measure of accuracy since their interpretation is different (the ranges are different). \n",
        "Hence a more easily interpretable measure of unfairness would be the distance of the score to 1. \n",
        "However, due to the nature of this ratio of probabilities, values above 1 are not directly comparable to the values under 1 - values above 1 \"overcorrect\" the ratio (the two groups would not be treated similarly). For that reason, we don't directly study the disparate impact but 1−min(disparate impact,1/disparate impact) to correct this issue.\n",
        "\n",
        "<i>Disparet impact simplified formula</i><br>\n",
        "\n",
        "𝑃𝑟(𝑌̂ =pos_label|𝐷=unprivileged)/𝑃𝑟(𝑌̂ =pos_label|𝐷=privileged)<br>\n",
        "\n",
        "#### *a) We plot for the validation dataset  1−min(disparate impact,1/disparate impact) and the balanced accuracy for thresholds between 0.01 and 0.99. Where would you set a threshold in relation to this new metric?  (you don't need to report a very specific threshold but simply give an approximate number) Explain your reasoning.*\n",
        "\n",
        "#### *b) Recall the threshold you had set earlier. Do these thresholds match? Reflect on that.*\n",
        "\n",
        "#### *c) Append to this plot the two curves for the two scores that compose the ratio in the calculation of the disparate impact. <br> Hint: you can find these scores in the outputs of the test() function.*\n",
        "\n",
        "#### *Assuming we want a balanced accuracy above 0.65, where would you set thresholds observing these metrics (you don't need to report very specific thresholds but simply give  approximate numbers)? Explain your reasoning. <br>Hint: you might want to set different thresholds in the case where you maximize each of the two metric, and in the case where you focus on disparate impact.*\n",
        "\n",
        "#### *d) Do the thresholds match for the different cases in c)? Reflect on that.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncR8kflXXU6v"
      },
      "source": [
        "Add as many cells as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APtNZpaHNN-J"
      },
      "outputs": [],
      "source": [
        "# Code "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTvM63_rer_U"
      },
      "source": [
        "amswers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTecYLsoXbBt"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aqRd-NsXbTK"
      },
      "source": [
        "<H3>To Go further: Existing tools and Metrics</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EijWb1kfIU03"
      },
      "source": [
        "\n",
        "\n",
        "**FairLearning Framwork**<br>\n",
        "Provides a ritch Observational Fairness Library of Metrics and Mitigation Approaches.<br>\n",
        "Provides many tools to measure, mitigate bias and to explain ML outputs\n",
        "For more information check the website and tutorials of <a href=https://fairlearn.org/><b>FairLearning</b></a>.\n",
        "<br><br>\n",
        "\n",
        "**IBM AI Fairness 360** <br>\n",
        "Provides many tools to measure, mitigate bias and to explain ML outputs.<br>\n",
        "For more information make use of the documentation of <a href=https://aif360.readthedocs.io/en/latest/index.html><b>AIF360</b></a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVkbcehmIU03"
      },
      "source": [
        "<br><br>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 64-bit ('3.9.15')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "vscode": {
      "interpreter": {
        "hash": "7a51f908579e300a02f10534cef0cd09f6905b9ea3f83df74d0f938cc2c2730e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
